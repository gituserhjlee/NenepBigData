{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['365dni.csv',\n",
       " 'AfterWeCollided.csv',\n",
       " 'Chhalaang.csv',\n",
       " 'Deadpool.csv',\n",
       " 'Dolittle.csv',\n",
       " 'Emma..csv',\n",
       " 'EnolaHolmes .csv',\n",
       " 'freaky.csv',\n",
       " 'Gisaengchung.csv',\n",
       " 'greenland.csv',\n",
       " 'Hamilton.csv',\n",
       " 'holidate.csv',\n",
       " 'homeAlone.csv',\n",
       " 'JingleJangleAChristmasJourney.csv',\n",
       " 'JiuJitsu.csv',\n",
       " 'Loimpossible.csv',\n",
       " 'LoveActually.csv',\n",
       " 'Ludo.csv',\n",
       " 'meganIsMissing.csv',\n",
       " 'MonsterProblems.csv',\n",
       " 'Mulan.csv',\n",
       " 'Nokeunokeu.csv',\n",
       " 'Rebecca.csv',\n",
       " 'SooraraiPottru.csv',\n",
       " 'Spider-ManIntotheSpider-Verse.csv',\n",
       " 'TheNewMutants.csv',\n",
       " 'TheTrialoftheChicago7.csv',\n",
       " 'TheWitches.csv',\n",
       " 'ThorRagnarok.csv',\n",
       " 'Unhinged.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"reviewDatas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.listdir(\"reviewDatas\")\n",
    "def load_data(path):\n",
    "    movie_review = []\n",
    "    ma = movie_review.append\n",
    "    for movie in path:\n",
    "        data = pd.read_csv(\"reviewDatas\\\\\"+movie, names = [\"idx\", \"review\"])\n",
    "        data = data.iloc[1:,1:]\n",
    "        review_list = []\n",
    "        ra = review_list.append\n",
    "        for i in range(len(data)):\n",
    "            ra(data.iloc[i,0])\n",
    "        ma(review_list)\n",
    "    return movie_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_review = load_data(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리 방안\n",
    "\n",
    "+ 이모티콘을 단어로 변환 후 중복된 이모티콘을 1개로 만들기   \n",
    "+ 단어의 길이가 1에서 2인 것 제거    \n",
    "+ 리뷰의 구두점들을 제거      \n",
    "+ 첫번째 단어가 대문자거나 대문자로 되어있는 모든 단어들 제거   \n",
    "+ 숫자 제거      \n",
    "+ 제거되지 않은 대문자 모임 소문자화 후 양끝 공백제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(review_list):\n",
    "    multi_emoji = re.compile(r'[:]{2,}[\\w_-]+')\n",
    "    shortword = re.compile(r'\\W*\\b\\w{1,2}\\b')\n",
    "    punc = re.compile(r'[\\W_]+')\n",
    "    first_upper = re.compile(r'\\s*[A-Z][a-z0-9]+')\n",
    "    digit = re.compile(r'\\d+')\n",
    "\n",
    "    token_list = []\n",
    "    ta = token_list.append\n",
    "    for i in range(len(review_list)):\n",
    "        review_list[i] = multi_emoji.sub('',emoji.demojize(review_list[i]))\n",
    "        review_list[i] = shortword.sub('',review_list[i])\n",
    "        review_list[i] = punc.sub(' ',review_list[i])\n",
    "        review_list[i] = first_upper.sub('',review_list[i])\n",
    "        review_list[i] = digit.sub('',review_list[i])\n",
    "        review_list[i] = shortword.sub('',review_list[i])\n",
    "        review_list[i] = review_list[i].lower()\n",
    "        review_list[i] = review_list[i].strip()\n",
    "\n",
    "        #토큰화\n",
    "        ta(re.split('\\s+',review_list[i]))\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0% 20.0% 30.0% 40.0% 50.0% 60.0% 70.0% 80.0% 90.0% 100.0% "
     ]
    }
   ],
   "source": [
    "all_token = []\n",
    "aa = all_token.append\n",
    "for idx,review_list in enumerate(movie_review):\n",
    "    token_list = preprocessing(review_list)\n",
    "    aa(token_list)\n",
    "    if (idx+1) % 3 == 0:\n",
    "        print(\"{}%\".format((idx+1) / len(movie_review) * 100), end = \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_token 리스트의 길이 30개(영화 수)    \n",
    "all_token\\[0\\]는 첫번째 영화의 token_list  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 불용어 처리\n",
    "\n",
    "추가사항   \n",
    "구글의 stopwords english와 합집합.   \n",
    "리뷰에 의도적으로 어퍼스토로피를 빼고 작성한 경우 존재.   \n",
    "stopwords가 작동을 하지 않음.    \n",
    "따라서 적당히 단어가 되지 않는 선에서 stopwords 추가   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    }
   ],
   "source": [
    "#불용어 목록 만들기\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "google_sw = \"a about above after again against all am an and any are aren't as at be because been before being below between both but by can't cannot could couldn't did didn't do does doesn't doing don't down during each few for from further had hadn't has hasn't have haven't having he he'd he'll he's her here here's hers herself him himself his how how's i i'd i'll i'm i've if in into is isn't it it's its itself let's me more most mustn't my myself no nor not of off on once only or other ought our ours ourselves out over own same shan't she she'd she'll she's should shouldn't so some such than that that's the their theirs them themselves then there there's these they they'd they'll they're they've this those through to too under until up very was wasn't we we'd we'll we're we've were weren't what what's when when's where where's which while who who's whom why why's with won't would wouldn't you you'd you'll you're you've your yours yourself yourselves\"\n",
    "google_sw = set(google_sw.split(' '))\n",
    "no_upper_sw = set(\"arent cant couldnt didnt doesnt dont hadnt hasnt hed hes heres hows id ill im ive isnt lets mustnt shant shed shes shouldnt thats theres theyd theyll theyre theyve wasnt wed weve werent whats whens wheres whos whys wont wouldnt youd youll youre youve\".split(' '))\n",
    "\n",
    "stop_words = stop_words | google_sw | no_upper_sw\n",
    "\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def elim_stopwords(all_token):\n",
    "    for token_list in all_token:\n",
    "        for i,li in enumerate(token_list):\n",
    "            token_list[i] = [item for item in li if item not in stop_words]\n",
    "    return all_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token = elim_stopwords(all_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pos-tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagging(all_token):\n",
    "    for i, token_list in enumerate(all_token):\n",
    "        try:\n",
    "            for j, li in enumerate(token_list):\n",
    "                token_list[j] = pos_tag(li)\n",
    "        except IndexError:\n",
    "            print(i,j)\n",
    "        except:\n",
    "            print(\"Someting else went wrong\")\n",
    "    return all_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 938\n",
      "8 759\n",
      "17 67\n",
      "20 1337\n",
      "23 287\n",
      "24 146\n",
      "26 25\n",
      "28 907\n"
     ]
    }
   ],
   "source": [
    "all_token = pos_tagging(all_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# index error 나는 리뷰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 첫번째 글자를 항상 대문자로 작성하였음...     \n",
    "    \n",
    "데드풀 938,\"Deadpool, Was The Perfect Comic Book Movie, Ryan Reynolds Was Born To Play The Character, And The Movie Is A Very Good Different Kind Of Movie, It's Fun To Watch! Has Great Jokes It's Fun! Funny! Has Great Wallbreakers! Good Amount Of Action! You Don't Want The Movie To End It's Been A While Sense I Seen A Superhero That's This Good And Perfect! Ryan Reynolds Is Inspiring In This Movie Makes You Wanna Become An Actor So You Can Play A Character Like This! This Movie Deserves To Be On Imdbs Top Movies, It Can't Get Better Than That, Hoping To See More Deadpool In The Future, One Of The Best Superhero/Antiheros Ever! Movie Had A Simple But Fun Story!\"    \n",
    "    \n",
    "기생충 759,\"I'm An Indian.I Watched It After A Lot Of Recommendation,But It Never Fullfilled My Expectations.The Movie Shows The Division In Between Peoples Such As High Class And Low Class,It Presents In The Way Of A Comedy Drama.I'm Not Satisfied On The Movie Maybe Because Of I'd Watch Lot Of Indian Movies Which Has These Kind Of Story.\"     \n",
    "    \n",
    "Ludo 67 \"A Nice Movie Which Has Everything In It. If Creators Cut Duration By 30 Minutes Then It's Became More Enjoyable.\"    \n",
    "     \n",
    "Mulan 1337,\"I Dislike When People Compare The Mulan Live Action Movie To The Original Animated Movie There Two Totally Different   Movies.I Thought The Cinematography Was Absolutely Astounding,The Characters Where Amazing And The Special Effects Where Great.\"   \n",
    "    \n",
    "SooraraiPottru 287 \"Good Direction Fabulous Acting Good Cinematography\"    \n",
    "    \n",
    "스파이더맨 146,\"Animation 10/10     \n",
    "Story 10/10     \n",
    "Direction 10/10     \n",
    "Script 10/10     \n",
    "Imagination 100/10Loved it....\"     \n",
    "\n",
    "TheTrialoftheChicago7 25, \"Performances: 10/10 Pacing: 7/10 Plot: 9/10 Writing: 10/10 Cinematography: 7/10 Soundtrack: 7/10        Enjoyability: 8/10\"         \n",
    "    \n",
    "나크나로크 907,Niiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiicccccccccccccccccccccccccccceeeeeeeeeeeeeeeeeeeeeeeeeeee     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 영화당 이런 리뷰가 1개씩 밖에 없으니 지워도 무방할 듯 싶습니다..!\n",
    "\n",
    "## 결측치 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-200981ca9e8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_token\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mall_token\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mall_token\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mall_token\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mall_token\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "# all_token[3].remove([''])\n",
    "# all_token[8].remove([''])\n",
    "# all_token[17].remove([''])\n",
    "# all_token[20].remove([''])\n",
    "# all_token[23].remove([''])\n",
    "# all_token[24].remove([''])\n",
    "# all_token[26].remove([''])\n",
    "# all_token[28].remove([''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "감성단어는 보통 형용사가 많기 때문에    \n",
    "Stemming은 과한 일반화가 될 수 있으므로 시행하지 않음   \n",
    "pos-tagging(품사 태깅) 후 Lemmatization만 시행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
